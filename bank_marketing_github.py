# -*- coding: utf-8 -*-
"""bank_marketing_github.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MaJ4y9gxlKvoz41dH3MNF0MfcnMjkuPr

# EDA

### Importing Libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
from sklearn import preprocessing
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.decomposition import PCA
from sklearn import model_selection
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns

"""### Read Train Data"""

data_train = pd.read_csv("bank-additional-full.csv", na_values =['NA']) # na_values =['NA'] tells pandas to treat the string 'NA' as a missing value.
columns = data_train.columns.values[0].split(';')
columns = [column.replace('"', '') for column in columns]
data_train = data_train.values
data_train = [items[0].split(';') for items in data_train]
data_train = pd.DataFrame(data_train,columns = columns)

data_train['job'] = data_train['job'].str.replace('"', '')
data_train['marital'] = data_train['marital'].str.replace('"', '')
data_train['education'] = data_train['education'].str.replace('"', '')
data_train['default'] = data_train['default'].str.replace('"', '')
data_train['housing'] = data_train['housing'].str.replace('"', '')
data_train['loan'] = data_train['loan'].str.replace('"', '')
data_train['contact'] = data_train['contact'].str.replace('"', '')
data_train['month'] = data_train['month'].str.replace('"', '')
data_train['day_of_week'] = data_train['day_of_week'].str.replace('"', '')
data_train['poutcome'] = data_train['poutcome'].str.replace('"', '')
data_train['y'] = data_train['y'].str.replace('"', '')

data_train.head()

"""### Read Test Data"""

data_test = pd.read_csv("bank-additional.csv", na_values =['NA'])
data_test = data_test.values
data_test = [items[0].split(';') for items in data_test]
data_test = pd.DataFrame(data_test,columns = columns)

data_test['job'] = data_test['job'].str.replace('"', '')
data_test['marital'] = data_test['marital'].str.replace('"', '')
data_test['education'] = data_test['education'].str.replace('"', '')
data_test['default'] = data_test['default'].str.replace('"', '')
data_test['housing'] = data_test['housing'].str.replace('"', '')
data_test['loan'] = data_test['loan'].str.replace('"', '')
data_test['contact'] = data_test['contact'].str.replace('"', '')
data_test['month'] = data_test['month'].str.replace('"', '')
data_test['day_of_week'] = data_test['day_of_week'].str.replace('"', '')
data_test['poutcome'] = data_test['poutcome'].str.replace('"', '')
data_test['y'] = data_test['y'].str.replace('"', '')

data_test.head()

"""### Preprocessing the data

This function convert categorical columns (columns containing text or string values representing categories) into numerical representations (For example, 'married' might become 0, 'single' might become 1, and 'divorced' might become 2.).
"""

def categorize(df):
    new_df = df.copy()
    le = preprocessing.LabelEncoder()

    new_df['job'] = le.fit_transform(new_df['job'])
    new_df['marital'] = le.fit_transform(new_df['marital'])
    new_df['education'] = le.fit_transform(new_df['education'])
    new_df['default'] = le.fit_transform(new_df['default'])
    new_df['housing'] = le.fit_transform(new_df['housing'])
    new_df['month'] = le.fit_transform(new_df['month'])
    new_df['loan'] = le.fit_transform(new_df['loan'])
    new_df['contact'] = le.fit_transform(new_df['contact'])
    new_df['day_of_week'] = le.fit_transform(new_df['day_of_week'])
    new_df['poutcome'] = le.fit_transform(new_df['poutcome'])
    new_df['y'] = le.fit_transform(new_df['y'])
    return new_df

"""The second line groups different types of basic education ('basic.6y', 'basic.4y', 'basic.9y') into a single category called 'basic'."""

data = pd.concat([data_train, data_test])
data.replace(['basic.6y','basic.4y', 'basic.9y'], 'basic', inplace=True)

"""### Checking for null values"""

data.isnull().sum()

"""No null values were discoverd

### Data Visualization
"""

sns.set(style="ticks", color_codes=True)
sns.countplot(y='job', data=data)

"""This line removes the rows from the dataset where the job information is unknown or missing, keeping only the rows with valid job information"""

data = data[data.job != 'unknown']

sns.countplot(y='marital', data=data)

data.marital.value_counts()

"""Remove rows with unknown values for 'marital' and 'loan'"""

data = data[data.marital != 'unknown']
data = data[data.loan != 'unknown']

sns.countplot(y='education', data=data)

data = data[data.education != 'illiterate']

data.describe()

"""Count of the output variable"""

sns.countplot(y='y', data=data)

"""From the above Picture, We can say that the data is imbalanced

categorize(data) is necessary to transform categorical features into a format suitable for machine learning algorithms, as many of them require numerical input. Example: if a column named "color" has values like "red", "green", and "blue", categorize might transform them into 0, 1, and 2, respectively

convert_objects(convert_numeric=True) ensures that all columns that can be represented as numbers are indeed stored as numerical data types for consistency and compatibility with numerical operations in pandas and other libraries. Example: if a column named "city" contains values like "New York", "London", and "Tokyo", convert_objects would likely leave it unchanged if we didn't call the categorize function
"""

data = categorize(data)
data = data.convert_objects(convert_numeric=True) # Deprecated, use this instead
#for col in data.columns:
#    data[col] = pd.to_numeric(data[col], errors='ignore')

"""### Checking for outliers using boxplots"""

sns.boxplot(x='y', y='duration', data=data)

sns.boxplot(x='y', y='education', data=data)

sns.boxplot(x='y', y='housing', data=data)

sns.boxplot(data['y'],data['age'])

sns.boxplot(data['y'],data['job'])

sns.boxplot(data['y'],data['campaign'])

"""### Removing outliers

np.logical_or(col_values<minimum, col_values>maximum) creates a Boolean array where True indicates an outlier (value is either less than minimum or greater than maximum).

If the Boolean array element is True (outlier), it replaces the value with the mean of the entire column (col_values.mean()).
If the Boolean array element is False (not an outlier), it keeps the original value.

Finally, the modified values are assigned back to the original column in the DataFrame (df).
"""

def remove_outliers(df, column , minimum, maximum):
    col_values = df[column].values
    df[column] = np.where(np.logical_or(col_values<minimum, col_values>maximum), col_values.mean(), col_values)
    return df

min_val = data["duration"].min()
max_val = 1500
data = remove_outliers(df=data, column='duration' , minimum=min_val, maximum=max_val)

min_val = data["age"].min()
max_val = 80
data = remove_outliers(df=data, column='age' , minimum=min_val, maximum=max_val)

min_val = data["campaign"].min()
max_val = 6
data = remove_outliers(df=data, column='campaign' , minimum=min_val, maximum=max_val)

"""### Dropping less meaningful columns"""

sns.countplot(x='education',hue='y',data=data)

sns.countplot(x='default', hue='y',data=data)

"""It is skewed to 0. So We can drop this."""

data = data.drop('default', axis=1)

sns.countplot(x='poutcome', hue='y', data=data) # poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')

"""So many non existent values. We can drop this"""

data = data.drop('poutcome',axis=1)

sns.countplot(x='loan',hue='y',data=data)

sns.countplot(x='contact',hue='y',data=data)

data = data.drop('contact',axis=1)

data = data.drop(['emp.var.rate','cons.price.idx','cons.conf.idx','euribor3m','nr.employed'],axis=1)

data.info()

data.head()

"""# Classification

### Splitting into train and test data
"""

X = data.drop('y',axis = 1).values
y = data['y'].values
X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.25, random_state=42)

scaler = StandardScaler()
scaler.fit(X_train)
X_train = scaler.fit_transform(X_train)

pca = PCA(n_components=10)
pca.fit(X_train)
X_train = pca.fit_transform(X_train)

X_train.shape

"""### Building different Models and validating using 10 fold cross validation"""

models = []
models.append(('LR', LogisticRegression()))
models.append(('LDA', LinearDiscriminantAnalysis()))
models.append(('KNN', KNeighborsClassifier()))
models.append(('Decison-Tree', DecisionTreeClassifier()))
models.append(('Gaussian', GaussianNB()))
models.append(('SVM', SVC()))
models.append(('RandForest',RandomForestClassifier(max_depth = 8, n_estimators = 120)))
models.append(('ADA', AdaBoostClassifier(n_estimators = 120)))

results = []
names = []
for name, model in models:
    kfold = model_selection.KFold(n_splits=10, random_state=42)
    cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')
    results.append(cv_results)
    names.append(name)
    msg = "{}: {}".format(name, cv_results.mean())
    print(msg)

"""### Results

Logistic Regression obtained the highest accuracy with lesser runtime and is more stable in the results. Even SVM and Random Forest obtained the similar accuracy but have higher runtime compared to Logistic Regession.
"""

sns.set(rc={'figure.figsize':(10,8)})
sns.boxplot(names,results)

"""### Testing with the test data"""

scaler.fit(X_test)
X_test = scaler.fit_transform(X_test)

pca.fit(X_test)
X_test = pca.fit_transform(X_test)

lr = LogisticRegression()
lr.fit(X_train, Y_train)
predictions = lr.predict(X_test)
print("Accuracy : ", accuracy_score(Y_test, predictions))
print("Confusion Matrix : \n",confusion_matrix(Y_test, predictions))
print("Classification Report: \n",classification_report(Y_test, predictions))